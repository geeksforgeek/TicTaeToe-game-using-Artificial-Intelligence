{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geeksforgeek/TicTaeToe-game-using-Artificial-Intelligence/blob/master/fashion_Mnist_simple_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "W57U111P3Tzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "d5f9c9f5-44db-4492-8d72-6299aabf1a9d"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 79.9MB 540kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.14.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.11.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (3.7.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.2.2)\n",
            "Collecting google-pasta>=0.1.2 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/96/adbd4eafe72ce9b5ca6f168fbf109386e1b601f7c59926a11e9d7b7a5b44/google_pasta-0.1.4-py3-none-any.whl (51kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 22.9MB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.7)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K    100% |████████████████████████████████| 419kB 20.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.33.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (40.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (0.14.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (2.8.0)\n",
            "Installing collected packages: google-pasta, tb-nightly, tf-estimator-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed google-pasta-0.1.4 tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ghZfYVnz3aKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d37a4bf5-2c02-4fa6-855f-c40360768477"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ppF8BYpm4EcD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist=tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bOXX0uhT4KuK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(training_images,training_labels),(test_images,test_labels)=mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "173-DAsI4VB0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "08zbh0Px4hGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1316
        },
        "outputId": "c6c137c5-d0fa-4086-e250-74fa5f51e016"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(training_images[10])\n",
        "print(training_images[10])\n",
        "print(training_labels[10])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0  11 142 200 106   0   0   0   0   0   0   0\n",
            "   85 185 112   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 152 214 217 194 236 216 187 149 135 153 211 217\n",
            "  231 205 217 188  34   0   0   0   0   0]\n",
            " [  0   0   0   0   0  66 185 166 180 181 190 211 221 197 146 198 206 191\n",
            "  168 190 172 188 175   0   0   0   0   0]\n",
            " [  0   0   0   0   0 135 153 160 175 180 170 186 187 190 188 190 187 174\n",
            "  195 185 174 161 175  59   0   0   0   0]\n",
            " [  0   0   0   0   0 161 147 160 170 178 177 180 168 173 174 171 185 184\n",
            "  185 172 171 164 174 120   0   0   0   0]\n",
            " [  0   0   0   0   2 175 146 145 168 178 181 185 180 184 178 179 187 191\n",
            "  193 190 181 171 172 158   0   0   0   0]\n",
            " [  0   0   0   0  35 177 155 140 151 172 191 187 186 187 186 187 182 191\n",
            "  194 188 180 161 161 185   0   0   0   0]\n",
            " [  0   0   0   0  59 170 153 141 120 154 160 161 172 168 166 161 165 172\n",
            "  170 164 139 149 162 166  21   0   0   0]\n",
            " [  0   0   0   0  79 145 160 214 123 128 153 160 164 158 157 154 155 170\n",
            "  165 141 195 193 152 166  61   0   0   0]\n",
            " [  0   0   0   0 100 157 225 245 175 113 174 158 158 160 155 160 164 178\n",
            "  188 135 185 240 201 172 108   0   0   0]\n",
            " [  0   0   0   0   0  31 174  28 126 153 166 152 158 158 160 161 157 168\n",
            "  191 188  18 132 159   7   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  82 187 159 153 157 158 162 164 164 154\n",
            "  187 190   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   3   5   0  37 175 158 155 162 158 160 162 165 153\n",
            "  177 205   0   0   3   3   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0  25 175 152 160 158 161 160 164 164 161\n",
            "  166 200   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   4   0  30 171 147 164 155 165 161 165 162 170\n",
            "  164 162   0   0   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   4   0  57 166 155 164 166 161 161 164 167 165\n",
            "  165 162  28   0   3   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   3   0 114 161 161 166 159 168 161 161 172 162\n",
            "  165 171  50   0   5   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0 149 157 167 172 159 172 164 161 172 170\n",
            "  160 171  89   0   4   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   4 171 164 166 173 159 179 166 160 174 167\n",
            "  162 166 128   0   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0  18 152 173 160 179 154 181 166 164 175 170\n",
            "  166 170 164   0   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   4   0  47 165 172 167 185 153 187 173 165 174 179\n",
            "  166 166 158   5   0   3   0   0   0   0]\n",
            " [  0   0   0   0   0   4   0  87 180 162 179 179 157 191 182 165 168 190\n",
            "  173 165 166  20   0   4   0   0   0   0]\n",
            " [  0   0   0   0   0   4   0 105 187 157 194 175 161 190 184 170 158 205\n",
            "  177 168 171  44   0   4   0   0   0   0]\n",
            " [  0   0   0   0   0   5   0 138 181 158 205 160 167 190 198 167 152 218\n",
            "  186 170 172  57   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   5   0 135 174 167 199 155 166 201 219 165 158 218\n",
            "  188 167 175  56   0   7   0   0   0   0]\n",
            " [  0   0   0   0   0   5   0 129 171 172 177 153 159 206 216 148 157 206\n",
            "  190 165 175  48   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   5   0 167 187 182 198 194 200 226 240 184 206 255\n",
            "  197 178 179  42   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0 115 135 113 106  85  82 108 133  83  90 121\n",
            "  120 110 158  18   0   3   0   0   0   0]]\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ET01Zkd74nPi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#now normalize the dataset\n",
        "training_images=training_images/255\n",
        "training_labels=training_labels/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9N3cpuIi5p5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "f0f97222-76b9-476f-e991-abc2920d8a47"
      },
      "cell_type": "code",
      "source": [
        "#design a single layes neural network \n",
        "\n",
        "model =tf.keras.sequential([keras.layers.Flatten(input_shape=(28,28)),\n",
        "                        keras.layers.Dense(128,activation=tf.nn.relu),\n",
        "                        keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "                        ])\n",
        "#sequential--that define a sequence of layers in neural network\n",
        "#flatten will make the 28*28 into 784*1 matrix dimension\n",
        "#Dense add a layer of neurons\n",
        "#Each layer of neurons need a activation function\n",
        "#softmax take a set of values and effectively chose a max value\n",
        "#Consider the effects of additional layers in the network. What will happen if you add another layer between the one with 512 and the final layer with 10.\n",
        "#we can add more layers just by typing keras.layers.Dense(56,activation=tf.nn.relu)\n",
        "#this will add one more layer to our neural netowrk with 56 neutron\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-90c484a85d36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model =tf.keras.sequential([keras.layers.Flatten(input_shape=(28,28)),\n\u001b[0m\u001b[1;32m      3\u001b[0m                         \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         ])\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.api._v2.keras' has no attribute 'sequential'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "LttzIfHZ7AgH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "c8f07daa-ecea-4b8b-bbcc-95d628c028b0"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.trian.AdamOptimizer(),loss=\"spare_categorial_crossentropy\")\n",
        "model.fit(trainig_images,training_labels,epoch=5)\n",
        "model.evaluate(test_images,test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])#to cross verify whether it's predicting correctly or not\n",
        "#Consider the impact of training for more or less epochs. Why do you think that would be the case?\n",
        "#so avoid overfitting and try to choose a epoch such that loss would be less and accuracy will be high\n",
        "\n",
        "#Try 15 epochs -- you'll probably get a model with a much better loss than the one with 5 Try 30 epochs -- you might see the loss value stops decreasing, and sometimes increases. This is a side effect of something called 'overfitting' which you can learn about [somewhere] and it's something you need to keep an eye out for when training neural networks. There's no point in wasting your time training if you aren't improving your loss, right! :\n",
        "#Earlier when you trained for extra epochs you had an issue where your loss might change. It might have taken a bit of time for you to wait for the training to do that, and you might have thought 'wouldn't it be nice if I could stop the training when I reach a desired value?' -- i.e. 95% accuracy might be enough for you, and if you reach that after 3 epochs, why sit around waiting for it to finish a lot more epochs....So how would you fix that? Like any other program...you have callbacks! Let's see them in action\n",
        "#this can be done by adding one function which will stop after a certain accuracy will be reached\n",
        "# #class myCallback(tf.keras.callbacks.Callback):\n",
        "#   def on_epoch_end(self, epoch, logs={}):\n",
        "#     if(logs.get('loss')<0.4):\n",
        "#       print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "#       self.model.stop_training = True\n",
        "\n",
        "# callbacks = myCallback()\n",
        "#model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c02e858032c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrian\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"spare_categorial_crossentropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainig_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclassifications\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifications\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "yqzHbzV59Sw0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}